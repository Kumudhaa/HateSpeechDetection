{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBj3oJohlZj"
      },
      "source": [
        "## Hate Speech and Offensive Language Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LXjM3SszrjV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KTL3Ccypda6u"
      },
      "outputs": [],
      "source": [
        "#importing the dataset\n",
        "df = pd.read_csv(\"hatespeech.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qWFU0bVZd1A8",
        "outputId": "ef551d48-1794-43c0-d39b-5ca7c4bc8c75"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech_count</th>\n",
              "      <th>offensive_language_count</th>\n",
              "      <th>neither_count</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   count  hate_speech_count  offensive_language_count  neither_count  class  \\\n",
              "0      3                  0                         0              3      2   \n",
              "1      3                  0                         3              0      1   \n",
              "2      3                  0                         3              0      1   \n",
              "3      3                  0                         2              1      1   \n",
              "4      6                  0                         6              0      1   \n",
              "5      3                  1                         2              0      1   \n",
              "6      3                  0                         3              0      1   \n",
              "7      3                  0                         3              0      1   \n",
              "8      3                  0                         3              0      1   \n",
              "9      3                  1                         2              0      1   \n",
              "\n",
              "                                               tweet  \n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
              "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
              "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  \n",
              "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n",
              "8  \" &amp; you might not get ya bitch back &amp; ...  \n",
              "9  \" @rhythmixx_ :hobbies include: fighting Maria...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVNV13PC3bdn",
        "outputId": "7b099153-eaac-4edc-b647-ee78a783ace4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24783, 6)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcUlsXhANLbX",
        "outputId": "a4769dc7-9133-4557-ea0f-76f78a0378c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['count', 'hate_speech_count', 'offensive_language_count',\n",
              "       'neither_count', 'class', 'tweet'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O95GByx_NNwf"
      },
      "outputs": [],
      "source": [
        "df=df[['tweet','class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Pu-u07Xe8UEN",
        "outputId": "1dc7cb54-b642-4722-f86d-442f186532cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  class\n",
              "0      !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
              "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
              "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
              "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
              "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1\n",
              "...                                                  ...    ...\n",
              "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...      1\n",
              "24779  you've gone and broke the wrong heart baby, an...      2\n",
              "24780  young buck wanna eat!!.. dat nigguh like I ain...      1\n",
              "24781              youu got wild bitches tellin you lies      1\n",
              "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...      2\n",
              "\n",
              "[24783 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtn480gChvbf"
      },
      "source": [
        "### Data Pre-processing using NLTK Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVuNktZTd2ra",
        "outputId": "70699da4-379f-487b-80b1-f0c876d9ce62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\KUMUDHAA\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\KUMUDHAA\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\KUMUDHAA\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lw7aCDozjmSt"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wnk4DgdyjdBA"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocess(text):\n",
        "  text = re.sub('[^a-zA-Z]', ' ',text)\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  return \" \".join(WordNetLemmatizer().lemmatize(word) for word in tokens if word not in stopwords.words('english'))\n",
        "\n",
        "# Apply preprocessing\n",
        "df['tweet'] = df[\"tweet\"].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cyOf7hAZkKup"
      },
      "outputs": [],
      "source": [
        "corpus = df['tweet'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rwIDA0zs9ujQ",
        "outputId": "e3926e52-4436-4084-d00d-e40224cdf87d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'madison x shit blow claim faithful somebody still fucking hoe'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RD4t8nAG9sAg",
        "outputId": "127ed640-1abb-4d61-cace-b7b9fafddf4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt mayasolovely woman complain cleaning house ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt mleew boy dat cold tyga dwn bad cuffin dat ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rt urkindofbrand dawg rt sbaby life ever fuck ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt c g anderson viva based look like tranny</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt shenikaroberts shit hear might true might f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>muthaf lie lifeasking pearl corey emanuel righ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>gone broke wrong heart baby drove redneck crazy</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>young buck wan na eat dat nigguh like aint fuc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>youu got wild bitch tellin lie</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  class\n",
              "0      rt mayasolovely woman complain cleaning house ...      2\n",
              "1      rt mleew boy dat cold tyga dwn bad cuffin dat ...      1\n",
              "2      rt urkindofbrand dawg rt sbaby life ever fuck ...      1\n",
              "3            rt c g anderson viva based look like tranny      1\n",
              "4      rt shenikaroberts shit hear might true might f...      1\n",
              "...                                                  ...    ...\n",
              "24778  muthaf lie lifeasking pearl corey emanuel righ...      1\n",
              "24779    gone broke wrong heart baby drove redneck crazy      2\n",
              "24780  young buck wan na eat dat nigguh like aint fuc...      1\n",
              "24781                     youu got wild bitch tellin lie      1\n",
              "24782  ruffled ntac eileen dahlia beautiful color com...      2\n",
              "\n",
              "[24783 rows x 2 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucrne8ShiCmM"
      },
      "source": [
        "### Converting text into numerical vector representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0-QmafmGzVGd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=50000) #setting the maximum number of words to be used to 50000 (most frequent)\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "tokenized_tweet = tokenizer.texts_to_sequences(corpus)\n",
        "vector =pad_sequences(tokenized_tweet, maxlen=30, padding='post')\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(tokenizer.word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pb7mzgFyEbo",
        "outputId": "4b1af062-8949-4ec9-c0e9-3c737d701ba6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33166"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWIMH1RRrXEA",
        "outputId": "4a955451-3cba-4ecb-9879-50727bb3678a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[    2, 11802,    97, ...,     0,     0,     0],\n",
              "       [    2,  7670,    87, ...,     0,     0,     0],\n",
              "       [    2,  5800,   656, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  277,  1954,    63, ...,     0,     0,     0],\n",
              "       [ 5495,     9,   860, ...,     0,     0,     0],\n",
              "       [ 9980, 33161, 33162, ...,     0,     0,     0]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RdIUb0ujrdq3"
      },
      "outputs": [],
      "source": [
        "X=vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1V0XTKLRDqm",
        "outputId": "6422578a-585e-4e19-9fb6-6ddc60c035ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (24783, 3)\n"
          ]
        }
      ],
      "source": [
        "Y = pd.get_dummies(df['class'], dtype=int).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_EVbCkmuHvb",
        "outputId": "d53b2422-523f-4ad5-a8d5-3c3243e0668f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       ...,\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jxQlEtZtvfb",
        "outputId": "ce5a2483-28b5-4d86-f6b9-deec2316af76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y[50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mooY6t1t1x0",
        "outputId": "5a0c7dfa-dfb1-4516-b6f8-72aa0abd99e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        rt mayasolovely woman complain cleaning house ...\n",
              "1        rt mleew boy dat cold tyga dwn bad cuffin dat ...\n",
              "2        rt urkindofbrand dawg rt sbaby life ever fuck ...\n",
              "3              rt c g anderson viva based look like tranny\n",
              "4        rt shenikaroberts shit hear might true might f...\n",
              "                               ...                        \n",
              "24778    muthaf lie lifeasking pearl corey emanuel righ...\n",
              "24779      gone broke wrong heart baby drove redneck crazy\n",
              "24780    young buck wan na eat dat nigguh like aint fuc...\n",
              "24781                       youu got wild bitch tellin lie\n",
              "24782    ruffled ntac eileen dahlia beautiful color com...\n",
              "Name: tweet, Length: 24783, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9AlOpQVqQX4h"
      },
      "outputs": [],
      "source": [
        "y=np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "al3T31UWRaUp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YXc6Lqog8q1m"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MieyfqN-RgC",
        "outputId": "331a0289-08aa-4f51-d255-72564b6cfe0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\hate speech detection\\venev\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dropout, Bidirectional\n",
        "\n",
        "embedding_vector_dim=50 ##features representation\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,embedding_vector_dim,input_length=30))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Bidirectional(LSTM(50)))\n",
        "model.add(Dropout(0.3))\n",
        "#model.add(LSTM(50))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SSdjyJkA-XI",
        "outputId": "0c63008e-1500-42d5-bd18-de31c3e220f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7608 - loss: 0.6790 - val_accuracy: 0.8916 - val_loss: 0.3365\n",
            "Epoch 2/10\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9022 - loss: 0.3111 - val_accuracy: 0.9024 - val_loss: 0.3128\n",
            "Epoch 3/10\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9252 - loss: 0.2291 - val_accuracy: 0.8951 - val_loss: 0.3364\n",
            "Epoch 4/10\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9342 - loss: 0.1868 - val_accuracy: 0.8845 - val_loss: 0.3721\n",
            "Epoch 5/10\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9656 - loss: 0.1212 - val_accuracy: 0.8907 - val_loss: 0.4517\n",
            "Epoch 6/10\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9769 - loss: 0.0794 - val_accuracy: 0.8790 - val_loss: 0.4518\n",
            "Epoch 7/10\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9861 - loss: 0.0510 - val_accuracy: 0.8734 - val_loss: 0.5010\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1fae4c2a080>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_split=0.33, epochs=10, batch_size=64, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFU7bL52BJqp",
        "outputId": "3bec98d2-f58f-432b-fcb1-fe9d18b6ced1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       465\n",
            "           1       0.92      0.96      0.94      6335\n",
            "           2       0.84      0.80      0.82      1379\n",
            "\n",
            "   micro avg       0.91      0.88      0.89      8179\n",
            "   macro avg       0.59      0.59      0.59      8179\n",
            "weighted avg       0.86      0.88      0.87      8179\n",
            " samples avg       0.88      0.88      0.88      8179\n",
            "\n",
            "Accuracy score :  0.8792028365325835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\hate speech detection\\venev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\hate speech detection\\venev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred=np.where(y_pred > 0.5, 1,0)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Accuracy score : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W91spJV3sNie"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Hate speech detected\n"
          ]
        }
      ],
      "source": [
        "def predict_on_user_input():\n",
        "  user_text = input(\"Enter your text: \")\n",
        "  user_text = preprocess(user_text)\n",
        "  tokens = user_text.split()\n",
        "  encoded_sequence = [word_index.get(token, 0) for token in tokens]  \n",
        "  padded_sequence = pad_sequences([encoded_sequence], maxlen=30, padding='post')\n",
        "\n",
        " \n",
        "  prediction = model.predict(padded_sequence)\n",
        "  if prediction[0][0] > 0.5:\n",
        "    print(\"Highly offensive and Hate speech detected\")\n",
        "  elif prediction[0][1] > 0.5:\n",
        "    print(\"Hate speech detected\")\n",
        "  else:\n",
        "    print(\"Positive\")\n",
        "  \n",
        "\n",
        "predict_on_user_input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle \n",
        "pickle.dump(model,open('model.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "pickle.dump(word_index,open('word_index.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
